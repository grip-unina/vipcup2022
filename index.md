This year the VIP Cup competition @ICIP2022 is organized by University Federico II of Naples and NVIDIA and
the aim is to distinguish real versus AI-based content in images.
Teams are requested to design a strategy for synthetic image detection by relying on image processing and machine learning techniques.

### Background

In recent years there have been astonishing advances in AI-based synthetic media generation. 
Thanks to deep learning methods it is now possible to generate visual data with a high level of realism. 
Although this opens up a large number of new opportunities, it also undermines the trustworthiness of media content and supports the spread of misinformation over the internet. 
Recent studies have proved that humans cannot reliably tell apart images generated by advanced GAN technologies
from pristine images. This raises legitimate concerns about the use of synthetic images for the most different purposes. 
In this context, there is a fundamental need to develop robust and automatic tools capable of distinguishing synthetic images from real ones. 

In the literature, there has been an intense research effort for reliable synthetic image detectors.
However, one of the main challenges in GAN image detection is generalization. 
In fact, if a detector is tested on the very same type of images seen in the training phase it will hardly fail. 
Unfortunately, this is not what happens in a realistic scenario, in fact new architectures 
and different ways of generating synthetic data are proposed with the evolution of technology. 
To operate successfully in the wild, a detector should i) be robust to image impairments, 
ii) work universally well across sources and iii) generalize well to new sources. 
Robustness to image impairments is essential, since most social networks resize and compress images to satisfy their internal constraints. 
These non-malicious operations destroy precious evidence, with a possible detrimental effect on detection performance. 
Universality is also a fundamental requirement, since the detector ignores the image source 
(which GAN architecture was used to generate it) and cannot use this information. 
Finally, the image under test may have been generated by a totally new architecture, 
and the detector should work well also in this condition.

### Challenge Organization

Competitors are asked to work in the challenging scenario where it is not known the method used to generate synthetic data.
More specifically the test data comprises: 
i) both fully synthetic images and partially manipulated ones, 
ii) generative models that include not only GANs, but also more recent diffusion-based models. 
Being able to discriminate synthetic images, fully and partially synthetic, 
vs pristine ones can represent a step forward to the advancement of forensics tools.

The challenge will consist of two stages: an open competition that any eligible team can participate in, 
and an invitation-only final competition. Eligible teams must submit their entries by September 19, 2022. 
The three teams with the highest performance will be selected by September 26, 2022 and invited to join the final competition. 
The final competition will be judged at ICIP 2022, which will be held on October 16-19, 2022.

Open Competition - Testset 1
Part 1 of the open competition is designed to give teams a simplified version of the problem at hand to become familiar with the task. 
Participants will be provided with a labeled training dataset of real and synthetic images. 
Synthetic images can be fully or partially synthetic. 
Images will undergo JPEG compression at different quality levels and resizing prior to compression.  
Teams will be provided with PYTHON scripts to apply these operations to the training dataset. 
Teams are requested to provide the executable code to the organizers in order to test the algorithms on the evaluation dataset.

Open Competition - Testset 2
Part 2 of the competition is designed to address a more challenging task: synthetic image detection on unseen models, 
i.e. synthetic data generated using architectures not present in training. The task remains the same as for Part 1. 
Teams are requested to provide the executable code to the organizers in order to test the algorithms on the evaluation dataset.

Final Competition
The three highest scoring teams from the open competition will be selected
and they can provide an additional submission.

``More information on training set and test sets will be available on 25 June on this page and on the Piazza class.``

### Prize for Finalists

The three teams with highest performance in the open competition will be selected as finalists and will be invited to participate in the final competition at ICIP 2022. The champion team will receive a grand prize of $5,000. The first and the second runner-up will receive a prize of $2,500 and $1,500, respectively, in addition to travel grants and complimentary conference registrations.

### Timeline

* 25 July, 2022: Release of Training-Set
* 8 August, 2022: Deadline of first submission
* 15 August, 2022: Publication of the ranking of the first submission on first Testset 
* 29 August, 2022: Deadline of second submission
* 5 Sectember, 2022: Publication of the ranking of the second submission on first Testset
* 8 Sectember, 2022:  Publication of the ranking of the first two submissions on second Testset
* 19 Sectember, 2022: Deadline of third submission
* 26 Sectember, 2022: Final ranking on both Testsets

#### Additional Information

General information and resources are [available on Piazza](https://piazza.com/configure-classes/summer2022/vipcup2022).

To set up a free account, use the access code "vipcup2022" to join as a student the "VIPCUP 2022: IEEE Video and Image Processing Cup" class.



### Organizing Committee

- Luisa Verdoliva, University Federico II of Naples, Italy
- Davide Cozzolino, University Federico II of Naples, Italy
- Koki Nagano, NVIDIA

#### Sponsor

This competition is sponsored by the IEEE Signal Processing Society and SPS Information Forensics and Security Committee

